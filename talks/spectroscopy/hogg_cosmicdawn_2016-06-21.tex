% to-do:
% ------
% - merge in population results
% - discuss limitations of everything we are doing

\documentclass[pdftex]{beamer}
%\input{vc}

% set paper size
% 1.77778 is the ratio of 16 to 9
%\setlength{\paperheight}{2.75in} % going small!
%\setlength{\paperwidth}{1.77778\paperheight}
% 1.33333 is the ratio of 4 to 3
\setlength{\paperheight}{3.0in} % way small!
\setlength{\paperwidth}{1.33333\paperheight}

% set lengths given paper
\setlength{\textheight}{0.95\paperheight}
\setlength{\textwidth}{0.85\paperwidth}

% import the next thing *after* the lengths and sizes
\input{./hogg_presentation} % hogg standard colors
\setbeamertemplate{footline}{David W. Hogg / 2015-06-21}

\title{Statistical techniques}
\author[David W. Hogg (NYU)]{David W. Hogg\\[1ex] {\small \textsl{(SCDA \& NYU \& MPIA)}}}
\date{Cosmic Dawn / 2016 June 21}

\newcommand{\conclusions}{%
\begin{frame}
  \frametitle{Summary}
  \begin{itemize}
  \item \textit{This talk is not a review talk!}
  \item Use very flexible models to marginalize out calibration issues.
  \item Use data-driven models when you don't believe the physical models.
  \item Use Bayes to mix together competing models.
  \end{itemize}
\end{frame}}

\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\conclusions

\begin{frame}
  \frametitle{Church of Bayes}
  \begin{itemize}
  \item A model is a \emph{likelihood function} and \emph{priors over nuisance parameters}.
    \begin{itemize}
    \item $p(D\given\theta,\alpha)$
    \item $p(\alpha)$
    \end{itemize}
  \item If you want to perform MCMC, you need priors over everything.
    \begin{itemize}
    \item $p(\theta)$ too
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Likelihood function}
  \begin{itemize}
  \item The point of Bayes is to produce likelihood functions!
    \begin{itemize}
    \item The likelihood is the thing that updates beliefs.
    \end{itemize}
  \item This is true for both observers and theorists.
  \item Likelihood functions are technically \emph{subjective}.
    \begin{itemize}
    \item They involve decisions.
    \item You use your judgement to make choices.
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Pragmatism}
  \begin{itemize}
  \item You can't make a measurement without a model.
    \begin{itemize}
    \item $p(D\given\theta,\alpha)$ and $p(\alpha)$
    \end{itemize}
  \item However, often we can't afford to live the dream.
    \begin{itemize}
    \item All other methods for making measurements can be seen as
      approximations to Bayes.
    \item (for example: estimate and uncertainty)
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Very important high-redshift science?}
  \begin{itemize}
  \item<1> \textit{Trigger warning:} self-aggrandizement
  \item<2-> Around 1995, with Judy Cohen I had the high-redshift record
    for a normal galaxy (something like $z=0.8$), \emph{but\ldots}
  \item<2-> In 1996, Roger Blandford and I wrote a paper called
    ``Gravitational Telescopes'', \emph{but\ldots}
  \item<2-> In 1996--1998 with Smail and Cohen I had the deepest
    (faintest) galaxy counts in the $U$ and $R$ bands, and (in 2000)
    at 3 microns \emph{but\ldots}
  \item<3> Lesson learned: In the high-redshift business, don't rest on
    your laurels!
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Paradox of astrophysics}
  \begin{itemize}
  \item The big secret of astronomy:
  \item<2-> All models are wrong!
    \begin{itemize}
    \item (strongly ruled out by the data)
    \end{itemize}
  \item<3> All data are wrong!
    \begin{itemize}
    \item (systematics and selections)
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Combining spectroscopy and photometry}
  \begin{itemize}
  \item \textit{``I have both spectroscopy and photometry of my sources, and I
    want to fit models. There are so many more pixels in the
    spectroscopy than the photometry, if I just multiply the
    likelihoods, the spectroscopy dominates, the photometry is
    ignored, and I get wrong answers!''} \\ ~\hfill --- Many
    astronomers
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Combining spectroscopy and photometry}
  {\footnotesize
  $$\ln p(D\given\theta)
     = -\frac{1}{2}\,\underbrace{\sum_{i} \frac{[D_i - M_i(\theta)]^2}{\sigma_i^2}}_{\mbox{photometry}}
       -\frac{1}{2}\,\underbrace{\sum_{j} \frac{[D_j - M_j(\theta)]^2}{\sigma_j^2}}_{\mbox{spectroscopy}}
  $$}
\end{frame}

\begin{frame}
  \frametitle{Combining spectroscopy and photometry}
  \begin{itemize}
  \item Why do we want to upweight the photometry and downweight the spectroscopy?
    \begin{itemize}
    \item Because we don't believe the calibration of the spectroscopy.
    \item Sky subtraction, unaccounted noise sources.
    \end{itemize}
  \item The right thing to do is to \emph{marginalize out the calibration} and etc.
    \begin{itemize}
    \item No reweighting is permitted!
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Combining spectroscopy and photometry}
  {\footnotesize
  $$\ln p(D\given\theta,\alpha)
     = -\frac{1}{2}\,\underbrace{\sum_{i} \frac{[D_i - M_i(\theta)]^2}{\sigma_i^2}}_{\mbox{photometry}}
       -\frac{1}{2}\,\underbrace{\sum_{j} \frac{[D_j - M_j(\theta,\alpha)]^2}{\sigma_j^2}}_{\mbox{spectroscopy}}
  $$} $$
    p(D\given\theta) = \int p(D\given\theta,\alpha)\,p(\alpha)\,\dd\alpha
  $$
\end{frame}

\newcommand{\fullframe}[1]{{%
      \setbeamertemplate{navigation symbols}{}%
      \setbeamertemplate{background canvas}{\includegraphics[width=\paperwidth]{#1}}%
      \begin{frame}[plain]\end{frame}}}
\fullframe{./forHogg.png}
\fullframe{./forHogg1.png}
\fullframe{./forHogg2.png}

\begin{frame}
  \frametitle{Combining spectroscopy and photometry {\footnotesize (Johnson \etal, in prep)}}
  \begin{itemize}
  \item The flexible calibration vector marginalization effectively down-weights the ``shape'' of the spectrum.
  \item The procedure \emph{obviates spectrophotometric calibration!}
  \end{itemize}
\end{frame}

\conclusions

\begin{frame}
  \frametitle{Models are wrong---Approaches}
  \begin{itemize}
  \item Use no model: Data-driven
  \item Use every model ever made!
  \item Hybrid approaches
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Data-driven models (my personal usage)}
  \begin{itemize}
  \item Make use of things you \emph{strongly believe}:
    \begin{itemize}
    \item noise model \& instrument resolution
    \item causal structure (shared parameters)
    \end{itemize}
  \item Capitalize on huge amounts of data.
  \item Use an exceedingly flexible model.
  \item (Concepts of train, validate, and test.)
  \item (Every situation will be \emph{bespoke}.)
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{\tc: label transfer for stars}
  \begin{itemize}
  \item A few of your stars have good labels (from somewhere).
  \item Can you use this to label the other stars?
  \item Why would you want to do this?
    \begin{itemize}
    \item<2> you don't have good models at your wavelengths?
    \item<2> you want two surveys to be on the same ``system''?
    \item<2> you have some stars at high SNR, some at low SNR?
    \item<2> you spent human time on some stars but can't on all?
    \end{itemize}
  \end{itemize}
\end{frame}

\newcommand{\flux}{f}
\newcommand{\fluxes}{\boldsymbol{\flux}}
\newcommand{\labels}{\boldsymbol{\ell}}
\newcommand{\pars}{\boldsymbol{\theta}}

\begin{frame}
  \frametitle{\tc: model}
  \begin{itemize}
  \item $\ln p(\fluxes_n\given\labels_n,\pars)$
  \item \emph{training step}: optimize w.r.t.\ parameters $\pars$ at fixed labels
    $\labels$ using training-set data
    \begin{itemize}
    \item linear least squares
    \item every wavelength $\lambda$ treated independently
    \end{itemize}
  \item \emph{test step}: optimize w.r.t.\ labels $\labels$ at fixed
    parameters $\pars$ using test-set (survey) data
    \begin{itemize}
    \item non-linear optimization
    \item every star treated independently
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{\tc\ {\footnotesize (Ness \etal, 1501.07604)}}
  \,\hfill\includegraphics<1>[height=\figureheight]{/Users/hogg/TheCannon/documents/paper1/plots/training_aspcap2.pdf}
          \includegraphics<2>[height=\figureheight]{/Users/hogg/TheCannon/documents/paper1/plots/training_mkn2.pdf}
          \includegraphics<3>[height=\figureheight]{/Users/hogg/TheCannon/documents/paper1/plots/takeout_histc.png}
          \includegraphics<4>[width=\figurewidth]{/Users/hogg/TheCannon/presentations/data_model_cyan.png}
          \includegraphics<5>[width=\figurewidth]{/Users/hogg/TheCannon/documents/paper1/plots/R1_continuum5.png}
\end{frame}

\begin{frame}
  \frametitle{\tc~2: {\footnotesize (Casey \etal, 1603.03040)}}
  \,\hfill\includegraphics<1>[                  width=\figurewidth]{regularized-model-validation.png}%
          \includegraphics<2>[trim=0 0 0 3.0in, width=\figurewidth]{regularized-model-validation.png}%
          \includegraphics<3>[trim=0 0 0 6.0in, width=\figurewidth]{regularized-model-validation.png}%
          \includegraphics<4>[trim=0 0 0 9.0in, width=\figurewidth]{regularized-model-validation.png}%
          \includegraphics<5>[                  width=0.5\figurewidth]{M15_comparison.png}%
          \includegraphics<6>[trim=0 0 0 4.0in, width=0.5\figurewidth]{M15_comparison.png}%
          \includegraphics<7>[trim=0 0 0 8.0in, width=0.5\figurewidth]{M15_comparison.png}%
          \includegraphics<8>[trim=0 0 0 12.in, width=0.5\figurewidth]{M15_comparison.png}%
          \includegraphics<9>[width=\figurewidth]{sparse-first-order-coefficients.png}%
\end{frame}

\begin{frame}
  \frametitle{Data-driven models}
  \begin{itemize}
  \item Huge successes (\eg, accuracy, precision, adoption of \tc).
  \item Rarely will you meet the \emph{training-data requirements}.
  \item Their output can be \emph{hard to interpret}
  \end{itemize}
\end{frame}

\conclusions

\begin{frame}
  \frametitle{How to decide among different models?}
  \begin{itemize}
  \item Different spectral template sets are different and give different answers!
  \item \emph{Don't decide.}
  \item Throw all models in, let Hierarchical Bayes sort them out.
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{How to decide among different models?}
  \begin{itemize}
  \item Every model template gets an adjustable prior probability!
  \item Learn the prior for every template \emph{and} the posterior template for every star.
  \item Bayes goes for \emph{parsimony}.
    \begin{itemize}
    \item the \emph{data decide} which models to keep
    \item we did this in the star--galaxy separation context
    \item (Fadely \etal, 1206.4306)
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Star--galaxy separation {\footnotesize (Fadely \etal, 1206.4306)}}
  \,\hfill\includegraphics<1>[height=\figureheight]{./fig2.pdf}
          \includegraphics<2>[height=\figureheight]{./fig8.pdf}
          \includegraphics<3>[height=\figureheight]{./fig9.pdf}
\end{frame}

\begin{frame}
  \frametitle{All models are wrong!}
  \begin{itemize}
  \item What is the future?
  \item It is the \emph{combination of these ideas}:
    \begin{itemize}
    \item Hierarchical Bayes will \emph{trim the list of models} to the models that work well.
    \item Data-driven models will capture the \emph{information in the residuals}.
    \item Something very flexible will be used to \emph{marginalize out calibration issues}.
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{BUT}
  \begin{itemize}
  \item None of this obviates \emph{building better physical models}!
    \begin{itemize}
    \item Physical models are \emph{interpretable} and \emph{the basis
      of everything we know}.
    \item All statistical projects are \emph{ultimately in
      the service of improving the physical models}.
    \end{itemize}
  \end{itemize}
\end{frame}

\conclusions

\end{document}
